---
title: "RampCodes_Figure1"
author: "Sarah Tennant & Matt Nolan"
date: "20/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Analysis of neurons recorded from the parahippocampal areas during virtual navigation

The aim of this analysis is to identify all ramp cells within a specified dataset (all mice or all days for one mouse) and perform analysis to investigate their firing properties. 
1. Identify cells that represent location by ramping their firing rate using LM modeling 
2. Subset data by model fit (r2 value)
3. Compare firing rates of cells in this group


To set up, including loading packages and data, first run SetUp.Rmd.

### ----------------------------------------------------------------------------------------- ###

### ----------------------------------------------------------------------------------------- ###

## Average firing rate (for LM modelling)

The linear model uses firing rate data binned in space. For this we want to load average firing rate over trials from the data frame for each cluster. 
- Map over "Rates_averaged" column and extract averaged rates
- Add position for each point (data is binned into 200, 1 cm bins )
- Insert result back into dataframe
- Do this for beaconed, nonbeaconed and probe trials

1. Write function to add position
```{r}
add_position <- function(df, session_id, cluster_id) {
  len = length(unlist(df))
  df <- tibble(Rates = unlist(df), Position = rep(1:len)) 
  if(all(is.na(df$Rates))){print(paste0("All NAs. Session: ", session_id, ". Cluster:", cluster_id))}
  df
}
```

2. Run on dataframe : Average trials with reward

input columns: 
Rates_averaged_rewarded_b = beaconed trials
Rates_averaged_rewarded_nb = non-beaconed and probe trials
Rates_averaged_rewarded_p = probe trials only
```{r}
spatial_firing <- spatial_firing %>%
  mutate(asr_b_rewarded = pmap(list(Rates_averaged_rewarded_b, session_id, cluster_id), add_position),
         asr_nb_rewarded = pmap(list(Rates_averaged_rewarded_nb, session_id, cluster_id), add_position),
         asr_p_rewarded = pmap(list(Rates_averaged_rewarded_p, session_id, cluster_id), add_position)
         )
```


### ----------------------------------------------------------------------------------------- ###

# Run simple linear model to examine relationship between firing rate and position
_note:for now we are only interested in the outbound region of the track (30 - 90 cm)_

1. Make function to run linear model
```{r}
lm_helper <- function(df,
                      startbin,
                      endbin) {
  # Check for NAs
  if (all(is.na(df$Rates))) {
    df <-
      tibble(
        r.squared = c(NA),
        p.value = c(NA),
        intercept = c(NA),
        slope = c(NA)
      )
    return(df)
  }

  df <- df %>%
    subset(Position >= startbin & Position <= endbin)
  df_fit <- lm(Rates ~ Position, data = df, na.action = na.exclude)

  # get the model parameters
  params <- select(glance(df_fit), r.squared, p.value)
  # get the coefficients
  coeffs <- tidy(df_fit)
  # combine the parameters and coefficients
  params$intercept <- coeffs$estimate[[1]]
  params$slope <- coeffs$estimate[[2]]
  return(params)
}
```

2. run lm on all cells.
Removes any previously generated results (select), fits the data (mutate) and then adds model outputs as columns to spatial firing (unnest_wider).
```{r}
spatial_firing <- spatial_firing %>%
  select(-contains('asr_b_o_rewarded_fit_')) %>%
  select(-contains('asr_nb_o_rewarded_fit_')) %>%
  select(-contains('asr_p_o_rewarded_fit_')) %>%
  mutate(asr_b_o_rewarded_fit = pmap(list(asr_b_rewarded, 30, 90), lm_helper),
         asr_nb_o_rewarded_fit = pmap(list(asr_nb_rewarded, 30, 90), lm_helper),
         asr_p_o_rewarded_fit = pmap(list(asr_p_rewarded, 30, 90), lm_helper)) %>%
  unnest_wider(asr_b_o_rewarded_fit, names_sep = "_", names_repair = "universal") %>%
  unnest_wider(asr_nb_o_rewarded_fit, names_sep = "_", names_repair = "universal") %>%
  unnest_wider(asr_p_o_rewarded_fit, names_sep = "_", names_repair = "universal")
```

Linear model results are stored in:
spatial_firing$asr_b_o_rewarded_fit_slope
spatial_firing$asr_b_o_rewarded_fit_intercept
spatial_firing$asr_b_o_rewarded_fit_p.value
spatial_firing$asr_b_o_rewarded_fit_r.squared


### ----------------------------------------------------------------------------------------- ###

## Identification of ramp cells in dataset 

Ramp like cells are identified by whether the coefficients of the linear model lie outside the 95% confidence intervals of the same result from 1000 shuffled data sets.


1. Function to generate shuffles
- shuffles spikes using sample() function
- runs lm
- extracts coefficients
- stores coefficients for each 1000 shuffles (less memory than saving 1000 shuffles)
```{r}
#library(gdata)
# shuffles defines the number of shuffes. Use a smaller value for testing.
shuffle_rates <- function(df, startbin, endbin, shuffles = 10) {
  df_modified <- data.frame(neuron=as.numeric(),
                 slope=as.numeric(), 
                 rsquared=as.numeric(), 
                 pval=vector())
  names(df_modified) <- c("neuron", "slope", "rsquared", "pval")
  x <- 1
  repeat {
  shuff_df <- tibble(Rates = sample(as.vector(unlist(df)),replace = TRUE, prob = NULL), Position = c(1:200))
  df_mod <- lm_helper(shuff_df, startbin, endbin)
  data <- data.frame(as.numeric(x), df_mod$slope, df_mod$r.squared, df_mod$p.value)
  names(data) <- c("neuron", "slope", "r.squared", "p.value")
  df_modified <- rbind(df_modified,data)

  x = x+1
  if (x == shuffles){ 
  break
  }
  }
return(df_modified)
}
```

2. Run if shuffles haven't already been generated. 

You can either run a crude shuffle by shuffling the firing rate binned in space per cell or extract shuffles from a cyclic shuffling procedure done in Python
Set "shuffles" accordingly for a crude shuffle or set to a low number as the nested tables created will be used in the next step to extract the cyclic shuffles 
(this won't affect the number of cyclic shuffles extracted per cell)
```{r}
shuffles <- 2

# Uncomment the line below to load pre-saved shuffled data
#spatial_firing <- readRDS(SpatialFiring_with_1000_shuffles.Rda)

# Check to see if the column shuffle_results exists. If it does then don't run again.
if(!"shuffle_results_b_o" %in% colnames(spatial_firing)) {
  spatial_firing <- spatial_firing %>%
    mutate(shuffle_results_b_o = pmap(list(Rates_averaged_rewarded_b, 30, 90, shuffles), shuffle_rates)) %>%
    mutate(shuffle_results_nb_o = pmap(list(Rates_averaged_rewarded_nb, 30, 90, shuffles), shuffle_rates)) %>%
    mutate(shuffle_results_p_o = pmap(list(Rates_averaged_rewarded_p, 30, 90, shuffles), shuffle_rates))
}

if (save_results == 1) {
  saveRDS(spatial_firing, "data_out/SpatialFiring_with_1000_shuffles_of.Rda")
  # And use this to save a truncated version. Useful for testing code.
  saveRDS(slice_head(spatial_firing, n = 5), "SpatialFiring_with_1000_shuffles_trunc.Rda")
}
```


2. Extract shuffled results from spike-level shuffle dataframe (this contains 1000 shuffles)
```{r}
# set shuffles to 1000 as in the .feather file, this is used downstream to extract shuffle slopes
shuffles <- 1000
path = file.path(getwd(),"all_mice_concatenated_shuffle_data_rewarded.feather")
shuffled_df <- read_feather(path)

# I will put the results from Python here (copy of previous results over the existing ones)
spatial_firing$spike_shuffle_results_b_o <- spatial_firing$shuffle_results_b_o  # I did this because this 'nested' format is needed
spatial_firing$spike_shuffle_results_nb_o <- spatial_firing$shuffle_results_nb_o  # I did this because this 'nested' format is needed
spatial_firing$spike_shuffle_results_p_o <- spatial_firing$shuffle_results_p_o  # I did this because this 'nested' format is needed
spatial_firing$row_names <- seq(1, nrow(spatial_firing), by=1)

# get list of cells based on session id + cluster id
# add unique id for each cell to both data frames
shuffled_df$unique_cell_id <- paste(shuffled_df$session_id, shuffled_df$cluster_id)
spatial_firing$unique_cell_id <- paste(spatial_firing$session_id, spatial_firing$cluster_id)
unique_cells = unique(shuffled_df[c("unique_cell_id")])
number_of_cells = nrow(unique_cells)
print('Number of cells in spike-level shuffle data:')
print(number_of_cells)

# iterate on list of cells and change 'spike_shuffle_results_b_o' column
for(i in 1:nrow(unique_cells)) {
  # these are the rows that correspond to the cell
  cell_rows <- shuffled_df %>% filter(unique_cell_id == toString(unique_cells[i,]))
  # get part of df that corresponds to shuffled data from the cell from outbound
  shuffled_results_b <- cell_rows %>% select(beaconed_r2_ob, beaconed_slope_ob, beaconed_p_val_ob)
  shuffled_results_nb <- cell_rows %>% select(non_beaconed_r2_ob, non_beaconed_slope_ob, non_beaconed_p_val_ob)
  shuffled_results_p <- cell_rows %>% select(probe_r2_ob, probe_slope_ob, probe_p_val_ob)
  
  # rename the collumns in shuffled_results to "slope", "r.squared", "p.value"
  names(shuffled_results_b)[names(shuffled_results_b) == "beaconed_r2_ob"] <- "r.squared"
  names(shuffled_results_b)[names(shuffled_results_b) == "beaconed_slope_ob"] <- "slope"
  names(shuffled_results_b)[names(shuffled_results_b) == "beaconed_p_val_ob"] <- "p.value"
  names(shuffled_results_nb)[names(shuffled_results_nb) == "non_beaconed_r2_ob"] <- "r.squared"
  names(shuffled_results_nb)[names(shuffled_results_nb) == "non_beaconed_slope_ob"] <- "slope"
  names(shuffled_results_nb)[names(shuffled_results_nb) == "non_beaconed_p_val_ob"] <- "p.value"
  names(shuffled_results_p)[names(shuffled_results_p) == "probe_r2_ob"] <- "r.squared"
  names(shuffled_results_p)[names(shuffled_results_p) == "probe_slope_ob"] <- "slope"
  names(shuffled_results_p)[names(shuffled_results_p) == "probe_p_val_ob"] <- "p.value"
  
  neuron_list <- seq(1, nrow(shuffled_results_b), by=1) # make list [1...1000]
  shuffled_results_b$neuron=neuron_list  # add 'neuron' column with shuffle ids
  shuffled_results_nb$neuron=neuron_list  # add 'neuron' column with shuffle ids
  shuffled_results_p$neuron=neuron_list  # add 'neuron' column with shuffle ids
  
  # find cell in ramp data frame that we are updating the shuffled for
  cell_index <- spatial_firing[spatial_firing$unique_cell_id==toString(unique_cells[i,]),]$row_names
  # put spike shuffle results in R df
  spatial_firing$spike_shuffle_results_b_o[cell_index] <- list(shuffled_results_b)
  spatial_firing$spike_shuffle_results_nb_o[cell_index] <- list(shuffled_results_nb)
  spatial_firing$spike_shuffle_results_p_o[cell_index] <- list(shuffled_results_p)
}

# Now I renamed the spike_shuffle_results_b_o, spike_shuffle_results_nb_o, spike_shuffle_results_p_o to
#                         shuffle_results_b_o,       shuffle_results_nb_o,       shuffle_results_p_o
# first drop the old columns
spatial_firing <- spatial_firing[,!grepl("^shuffle_results_b_o",names(spatial_firing))]
spatial_firing <- spatial_firing[,!grepl("^shuffle_results_nb_o",names(spatial_firing))]
spatial_firing <- spatial_firing[,!grepl("^shuffle_results_p_o",names(spatial_firing))]

# then rename the newly created columns
names(spatial_firing)[names(spatial_firing) == "spike_shuffle_results_b_o"] <- "shuffle_results_b_o"
names(spatial_firing)[names(spatial_firing) == "spike_shuffle_results_nb_o"] <- "shuffle_results_nb_o"
names(spatial_firing)[names(spatial_firing) == "spike_shuffle_results_p_o"] <- "shuffle_results_p_o"
```



### ---------------------------------------------------------------------------- ### 

### classify neurons based on shuffle activity

If outside the 95% of the shuffled data set, a neuron is considered to have ramp like activity along the track. 

First, extract the 5 % and 95 % limits of 1000 shuffles for each neuron 

1. write function to find min and max slope for shuffled datasets 
```{r}

extract_min_shuffle_slopes <- function(df){
  df <- tibble(slopes = unlist(df$slope), r.squared = unlist(df$r.squared))
  if (all(is.na(df$slopes))) {
    return(NA)
  }
  min_slope_o <- quantile(as.numeric(unlist(df$slopes)), c(.05, .95)) [[1]][1]
  return(min_slope_o)
}

extract_max_shuffle_slopes <- function(df){
  df <- tibble(slopes = unlist(df$slope), r.squared = unlist(df$r.squared))
    if (all(is.na(df$slopes))) {
    return(NA)
  }
  max_slope_o <- quantile(as.numeric(unlist(df$slopes)), c(.05, .95)) [[2]][1]
  return(max_slope_o)
}

```

2. Run on all neurons
```{r}
spatial_firing <- spatial_firing %>%
  select(-contains('shuffle_min_slope_')) %>%
  select(-contains('shuffle_max_slope_')) %>%
  mutate(shuffle_min_slope_b_o = map_dbl(shuffle_results_b_o, extract_min_shuffle_slopes),
         shuffle_max_slope_b_o = map_dbl(shuffle_results_b_o, extract_max_shuffle_slopes),
         shuffle_min_slope_nb_o = map_dbl(shuffle_results_nb_o, extract_min_shuffle_slopes),
         shuffle_max_slope_nb_o = map_dbl(shuffle_results_nb_o, extract_max_shuffle_slopes),
         shuffle_min_slope_p_o = map_dbl(shuffle_results_p_o, extract_min_shuffle_slopes),
         shuffle_max_slope_p_o = map_dbl(shuffle_results_p_o, extract_max_shuffle_slopes))

```


We also want to extract slopes, r2 and pvalues of the 1000 shuffles for each neuron

1. Extract shuffle results (slopes and r2 for each shuffle)

2. run on all neurons
```{r}
spatial_firing <- spatial_firing %>%
  select(-contains('shuffle_results_b_o_')) %>%
  select(-contains('shuffle_results_nb_o_')) %>%
  select(-contains('shuffle_results_p_o_')) %>%
  select(-contains('adjust_pval_')) %>%
  unnest_wider(shuffle_results_b_o, names_sep = "_", names_repair = "universal") %>%
  unnest_wider(shuffle_results_nb_o, names_sep = "_", names_repair = "universal") %>%
  unnest_wider(shuffle_results_p_o, names_sep = "_", names_repair = "universal")
```


Then we want to correct the pvals of the lm, to account for multiple comparisons

1. put all pvalues into tibble then adjust using p.adjust from - package
```{r}
p_vals_b <- tibble(pvals = spatial_firing$asr_b_o_rewarded_fit_p.value)
adu_p_b <- tibble(adjust_pval_b_o = p.adjust(p_vals_b$pvals, "BH"))

```

2. bind new adjusted pvalues to dataframe
```{r}
spatial_firing <- cbind(spatial_firing, adu_p_b)
```

3. do the same for non-beaconed trials
```{r}
p_vals_nb <- tibble(pvals = spatial_firing$asr_nb_o_rewarded_fit_p.value)
adu_p_nb <- tibble(adjust_pval_nb_o = p.adjust(p_vals_nb$pvals, "BH"))
spatial_firing <- cbind(spatial_firing, adu_p_nb)
```

4. do the same for probe trials 
```{r}
p_vals_p <- tibble(pvals = spatial_firing$asr_p_o_rewarded_fit_p.value)
adu_p_p <- tibble(adjust_pval_p_o = p.adjust(p_vals_p$pvals, "BH"))
spatial_firing <- cbind(spatial_firing, adu_p_p)
```


### ----------------------------------------------------------------------------------------- ### 

Now we want to classify neurons, taking the adjusted significance into account

```{r}
compare_slopes <-
  function(min_slope = 1,
           max_slope = 1,
           slope = 1,
           pval = 1) {
    if (any(is.na(list(min_slope, max_slope, slope, pval)))) {
      return("Unclassified")
    }
    if (pval > 0.01) {
      return("Unclassified")
    } else if (slope < min_slope & pval < 0.01) {
      return("Negative")
    } else if (slope > max_slope & pval < 0.01) {
      return("Positive")
    } else if (slope > min_slope & slope < max_slope) {
      return("Unclassified")
    } else {
      return("Unclassified")
    }
  }

spatial_firing <- spatial_firing %>%
  select(-contains('lm_group_')) %>%
  mutate(
    lm_group_b = pmap(
      list(
        shuffle_min_slope_b_o,
        shuffle_max_slope_b_o,
        asr_b_o_rewarded_fit_slope,
        adjust_pval_b_o
      ),
      compare_slopes
    ),
    lm_group_nb = pmap(
      list(
        shuffle_min_slope_nb_o,
        shuffle_max_slope_nb_o,
        asr_nb_o_rewarded_fit_slope,
        adjust_pval_nb_o
      ),
      compare_slopes
    ),
    lm_group_p = pmap(
      list(
        shuffle_min_slope_p_o,
        shuffle_max_slope_p_o,
        asr_p_o_rewarded_fit_slope,
        adjust_pval_p_o
      ),
      compare_slopes
    )
  )

```


Linear model classification is stored in:
spatial_firing$lm_group_b
spatial_firing$lm_group_nb
spatial_firing$lm_group_p


### ---------------------------------------------------------------------------- ### 

### Classify neurons based on their ramp activity in the homebound region, similar to that done above. 

### ---------------------------------------------------------------------------- ### 


# Run simple linear model to examine relationship between firing rate and position
_note:for now we are only interested in the homebound region of the track (110 - 170 cm)_


1. Make function to run linear model

Use lm_helper defined above.


2. run lm on all cells.
Removes any previously generated results (select), fits the data (mutate) and then adds model outputs as columns to spatial firing (unnest_wider).
```{r}
spatial_firing <- spatial_firing %>%
  select(-contains('asr_b_h_rewarded_fit_')) %>%
  select(-contains('asr_b_h_rewarded_fit_')) %>%
  select(-contains('asr_b_h_rewarded_fit_')) %>%
  select(-contains('asr_nb_h_rewarded_fit_')) %>%
  select(-contains('asr_nb_h_rewarded_fit_')) %>%
  select(-contains('asr_nb_h_rewarded_fit_')) %>%
  select(-contains('asr_p_h_rewarded_fit_')) %>%
  select(-contains('asr_p_h_rewarded_fit_')) %>%
  select(-contains('asr_p_h_rewarded_fit_')) %>%
  mutate(asr_b_h_rewarded_fit = pmap(list(asr_b_rewarded, 110, 170), lm_helper),
         asr_nb_h_rewarded_fit = pmap(list(asr_nb_rewarded, 110, 170), lm_helper),
         asr_p_h_rewarded_fit = pmap(list(asr_p_rewarded, 110, 170), lm_helper)) %>%
  unnest_wider(asr_b_h_rewarded_fit, names_sep = "_", names_repair = "universal") %>%
  unnest_wider(asr_nb_h_rewarded_fit, names_sep = "_", names_repair = "universal") %>%
  unnest_wider(asr_p_h_rewarded_fit, names_sep = "_", names_repair = "universal")
```

Linear model results are stored in:
spatial_firing$asr_b_h_rewarded_fit_pval
spatial_firing$asr_b_h_rewarded_fit_slope
spatial_firing$asr_b_h_rewarded_fit_r.squared


### ---------------------------------------------------------------------------- ### 


## Identification of homebound ramp cells in dataset 

Ramp like cells are identified by whether the coefficients of the linear model lie outside the 95% confidence intervals of the same result from 1000 shuffled datasets

Beause the homebound zone is the same length as the outbound zone, and as shuffling is across the full track length, we can use the shuffle results previously generated.

### classify neurons based on shuffle activity

If outside the 95% of the shuffled dataset, a neuron is considered to have ramp like activity along the track. 

First we want to correct the pvals of the lm, to account for multiple comparisons

1. put all pvalues into tibble then adjust using p.adjust from - package
```{r}
p_vals_b <- tibble(pvals = spatial_firing$asr_b_h_rewarded_fit_p.value)
adu_p_b <- tibble(adjust_pval_b_h = p.adjust(p_vals_b$pvals, "BH"))

```

2. bind new adjusted pvalues to dataframe
```{r}
spatial_firing <- cbind(spatial_firing, adu_p_b)
```

3. do the same for non-beaconed trials
```{r}
p_vals_nb <- tibble(pvals = spatial_firing$asr_nb_h_rewarded_fit_p.value)
adu_p_nb <- tibble(adjust_pval_nb_h = p.adjust(p_vals_nb$pvals, "BH"))
spatial_firing <- cbind(spatial_firing, adu_p_nb)
```

3. do the same for probe trials 
```{r}
p_vals_p <- tibble(pvals = spatial_firing$asr_p_h_rewarded_fit_p.value)
adu_p_p <- tibble(adjust_pval_p_h = p.adjust(p_vals_p$pvals, "BH"))
spatial_firing <- cbind(spatial_firing, adu_p_p)
```

Now we want to classify neurons, taking the adjusted significance into account

Uses the function compare_slopes from above.

```{r}

spatial_firing <- spatial_firing %>%
  mutate(
    lm_group_b_h = pmap(
      list(
        shuffle_min_slope_b_o,
        shuffle_max_slope_b_o,
        asr_b_h_rewarded_fit_slope,
        adjust_pval_b_h
      ),
      compare_slopes
    ),
    lm_group_nb_h = pmap(
      list(
        shuffle_min_slope_nb_o,
        shuffle_max_slope_nb_o,
        asr_nb_h_rewarded_fit_slope,
        adjust_pval_nb_h
      ),
      compare_slopes
    ),
    lm_group_p_h = pmap(
      list(
        shuffle_min_slope_p_o,
        shuffle_max_slope_p_o,
        asr_p_h_rewarded_fit_slope,
        adjust_pval_p_h
      ),
      compare_slopes
    )
  )

```

Linear model classification is stored in:
spatial_firing$lm_group_b_h
spatial_firing$lm_group_nb_h
spatial_firing$lm_group_p_h



### ----------------------------------------------------------------------------------------- ###
### How many neurons passed criteria in the linear model ? 

1. get numbers of cells for each lm group (positive/negative/unclassified)
```{r}
ramps <- nrow(subset(spatial_firing, lm_group_b == "Negative" | lm_group_b == "Positive" | lm_group_b_h == "Negative" | lm_group_b_h == "Positive"))
```

2. find and plot proportions for ramp types in dataset
```{r}
start <- nrow(subset(spatial_firing, lm_group_b == "Negative"))/nrow(spatial_firing)*100
reward <- nrow(subset(spatial_firing, lm_group_b == "Positive"))/nrow(spatial_firing)*100
nonslope <- nrow(subset(spatial_firing, lm_group_b == "Unclassified"))/nrow(spatial_firing)*100
```


### How much of the shuffled dataset is past criteria? 
1. Extract shuffled slopes and rsquared values. 
```{r}
shuff_slopes <- tibble(slopes = unlist(spatial_firing$shuffle_results_b_o_slope), 
                       r2 = unlist(spatial_firing$shuffle_results_b_o_r.squared), 
                       pval = unlist(spatial_firing$shuffle_results_b_o_p.value), 
                       min_slope = rep(spatial_firing$shuffle_min_slope_b_o, times = shuffles), 
                       max_slope = rep(spatial_firing$shuffle_max_slope_b_o, times = shuffles))
```


2. Classify shuffled cells based on shuffled distribution
```{r}
shuff_slopes <- shuff_slopes %>%
  mutate(
    shuff_lm_group_b = pmap(
      list(
        min_slope,
        max_slope,
        slopes,
        pval
      ),
      compare_slopes
    )
  )
```


3. Calculate proportion of cells in the shuffled datasets that pass criteria
-calculate total number of shuffles (cells x 999)
```{r}
total_shuffles <- nrow(shuff_slopes)
```

-calculate how many shuffled datasets have positive or negative slopes
```{r}
shuff_ramps <- nrow(subset(shuff_slopes,shuff_lm_group_b == "Positive" | shuff_lm_group_b == "Negative" ))
```

-calculate how many shuffles are unclassified
```{r}
non_shuff_ramps <- nrow(subset(shuff_slopes,shuff_lm_group_b == "Unclassified" | shuff_lm_group_b == "NA" ))
```

-calculate percentage shuffles that are not ramps
```{r}
non_shuff_ramps_percentage <- nrow(subset(shuff_slopes,shuff_lm_group_b == "Unclassified" | shuff_lm_group_b == "NA"))/nrow(shuff_slopes)*100

```


### ------------------------------------------------------------------------------------------ ### 


Now, we can classify cells based on their activity in the outbound and homebound region

i.e. pospos = positive in outbound, positive in homebound
i.e. posneg = positive in outbound, negative in homebound

1. write function to mark cells based on groups
```{r}
mark_track_category <- function(outbound, homebound){
  if( outbound == "Positive" & homebound == "Negative") {
    return( "posneg" ) 
  } else if( outbound == "Positive" & homebound == "Positive") {
    return( "pospos" )
  } else if( outbound == "Negative" & homebound == "Positive") {
    return( "negpos" )
  } else if( outbound == "Negative" & homebound == "Negative") {
    return( "negneg" )
  } else if( outbound == "Negative" & homebound == "Unclassified") {
    return( "negnon" )
  } else if( outbound == "Positive" & homebound == "Unclassified") {
    return( "posnon" )
  } else {
    return("None")
  }
}

```

2. run on all cells
```{r}
spatial_firing <- spatial_firing %>%
  select(-contains('track_category')) %>%
  mutate(track_category = map2(lm_group_b, lm_group_b_h, mark_track_category))

```


1. write function to mark cells based on groups
```{r}
mark_numeric_track_category <- function(outbound, homebound){
  if( outbound == "Positive" & homebound == "Negative") {
    return( as.numeric(2) ) 
  } else if( outbound == "Positive" & homebound == "Positive") {
    return( as.numeric(1) )
  } else if( outbound == "Negative" & homebound == "Positive") {
    return( as.numeric(5) )
  } else if( outbound == "Negative" & homebound == "Negative") {
    return( as.numeric(4) )
  } else if( outbound == "Negative" & homebound == "Unclassified") {
    return( as.numeric(6) )
  } else if( outbound == "Positive" & homebound == "Unclassified") {
    return( as.numeric(3) )
  } else {
    return(as.numeric(0))
  }
}

```

2. run on all cells
```{r}
spatial_firing <- spatial_firing %>%
  mutate(track_category_numeric = map2(lm_group_b, lm_group_b_h, mark_numeric_track_category))

```


1. How many ramps in total in the dataset?
```{r}
ramps <- nrow(subset(spatial_firing, track_category_numeric != 0))
```


### ------------------------------------------------------------------------------------------ ### 

## Does firing rate reset or continue across the reward zone region? 

### ------------------------------------------------------------------------------------------ ### 

Now, we want to find out if within pospos and negneg groups - are their firing rate reset or continue across the reward region?

To do this, we will predict the firing rate on the homebound zone from the activity in the outbound. Then find the difference between the predicted and real data to determine if cells have reset or continued. 


First, normalise firing rates. 


1. make function to load rates and normalise
```{r}
normalise_rates <- function(df1, df2){
  df <- c(df1, df2)
  df <- tibble(Rates = unlist(df), Position = rep(1:400))
  x <- scale(df$Rates, center=TRUE, scale=TRUE)
  x <- x[1:200]
  return(x)
}
```

2. run on all cells
```{r}
spatial_firing <- spatial_firing %>%
  mutate(normalised_rates = map2(Rates_averaged_rewarded_b, Rates_averaged_rewarded_nb,normalise_rates)) %>%
  mutate(normalised_rates_nb = map2(Rates_averaged_rewarded_nb,Rates_averaged_rewarded_b, normalise_rates)) %>%
  mutate(normalised_rates_p = map2(Rates_averaged_rewarded_p,Rates_averaged_rewarded_b, normalise_rates)) 

```

Then, predict firing rate in homebound region based on fit from real data in outbound region

1. make function to predict firing rate
```{r}
lm_predict <- function(df){
  new.data <- data.frame(Position =df$Position)
}
```

3. Predict mean and confidence intervals for firing rate at the start of the homebound zone (track positions 110 to 115 cm) based on firing in the outbound zone (30 to 90 cm).
```{r}
predict_homebound <- function(df, fit_start = 30, fit_end = 90, predict_start = 110, predict_end = 115){
  # check for NAs
  if(all(is.na(df))) 
    return(NA)
  # Make track column
  df <- tibble(Rates = unlist(df), Position=rep(1:200))
  # fit
  model <- lm(Rates ~ Position, data = filter(df, Position >= fit_start, Position <= fit_end))
  # predict
  homebound_prediction_pos <- tibble(Position = rep(1:200))
  homebound_prediction <- predict(model, newdata = homebound_prediction_pos, interval = "prediction", level = 0.99) 
  as.tibble(homebound_prediction)
}

```

Test whether data lies outside of confidence intervals
```{r}
offset_test <- function(rates, lwr, upr){
    # check for NAs
 if(all(is.na(rates))) 
    return(NA)
  rates <- mean(as.double(rates[110:115]))
  upr <- mean(as.double(upr[110:115]))
  lwr <- mean(as.double(lwr[110:115]))
 if(rates > upr) {
   return("Pos")
 }

 if (rates <= lwr) {
   return("Neg")
 }
    return("None")

}
```

Calculate difference between mean rate and predicted mean rate at the start of the homebound zone
```{r}
calc_predict_diff <- function(rates, fit)
{
  diff <- mean(as.double(rates[110:115])) - mean(as.double(fit[110:115]))
  }
```

2. Run on all neurons
```{r}
spatial_firing <- spatial_firing %>%
  select(-contains('predict_params_')) %>%
  mutate(predict_params = map(normalised_rates, predict_homebound)) %>%
  unnest_wider(predict_params, names_sep = "_", names_repair = "universal") 

spatial_firing <- spatial_firing %>%
  mutate(offset = pmap_chr(list(normalised_rates, predict_params_lwr, predict_params_upr), offset_test),
         predict_diff = map2_dbl(normalised_rates, predict_params_fit, calc_predict_diff))

```


### ------------------------------------------------------------------------------------------ ### 

### ------------------------------------------------------------------------------------------ ### 

Now, we can classify cells based on their predicted activity. 

1. Function to classify neurons based on offset 

```{r}
mark_reset_group_predict <- function(offset){
  if (is.na(offset) ) {
    return( "None" )
  } else if( offset == "None") {
    return( "Continuous" )
  } else if( ( offset == "Neg" ||  offset == "Pos")) {
    return( "Reset" ) 
  }
}

```

2. Run on all cells
```{r}
spatial_firing <- spatial_firing %>%
  mutate(reset_group = map(offset, mark_reset_group_predict))

```



### ------------------------------------------------------------------------------------------ ### 



## plot bar chart of mean apsolute difference between predicted and real

- do only for neurons that have slopes in outbound zone
- do this for both negative and positive slopes in the outbound zone

1. extract neurons that are ++ or -- on beaconed trials
```{r}
df_position_pi <- spatial_firing %>%
  filter(lm_group_b == "Positive" | lm_group_b == "Negative")  #%>% 

```

4. Plot bar charts - positive neurons
```{r}
ggplot(data=subset(df_position_pi, lm_group_b == "Positive"), aes(x = unlist(predict_diff), fill=as.factor(unlist(reset_group)))) +
  coord_cartesian(xlim=c(-6,6)) +
  geom_histogram(aes(y=..count..), alpha=0.5) +
  scale_fill_manual(values=c(  "grey", "chartreuse3","chartreuse3")) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 3)) +
  labs(y="Density", x="") +
  theme_classic() +
  theme(axis.text.x = element_text(size=13),
        axis.text.y = element_text(size=13),
        legend.position="bottom", 
        legend.title = element_blank(),
        text = element_text(size=13), 
        legend.text=element_text(size=13), 
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)))

if (save_figures == 1) {
  ggsave(file = "plots/PredictHomeboundMean_positive.png",width = 4, height = 2.5)
}
```

5. Plot bar charts - Negative neurons
```{r}

ggplot(data=subset(df_position_pi,lm_group_b == "Negative"), aes(x = unlist(predict_diff), fill=as.factor(unlist(reset_group)))) +
  coord_cartesian(xlim=c(-5,5)) +
  geom_histogram(aes(y=..count..), alpha=0.5) +
  scale_fill_manual(values=c( "grey", "violetred2","violetred2")) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 3)) +
  labs(y="Density", x="") +
  theme_classic() +
  theme(axis.text.x = element_text(size=13),
        axis.text.y = element_text(size=13),
        legend.position="bottom", 
        legend.title = element_blank(),
        text = element_text(size=13), 
        legend.text=element_text(size=13), 
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)))

if (save_figures == 1) {
  ggsave(file = "plots/PredictHomeboundMean_negative.png",width = 4, height = 2.5)
}
```




### ------------------------------------------------------------------------------------------ ### 


## now plot scatter of slopes for outbound and slopes for homebound with neurons marked accordng to whether they are reset or continuous

1. Here we subset neurons based on positive, negative or unclassified in the linear model and either reset or contiuous firing. 
```{r}
position_neurons_reset <- spatial_firing  %>% 
  filter(lm_group_b == "Positive" | lm_group_b == "Negative")  %>% 
  filter(reset_group == "Reset")

position_neurons_continuous <- spatial_firing  %>% 
  filter(lm_group_b == "Positive" | lm_group_b == "Negative")  %>% 
  filter(reset_group == "Continuous")

position_neurons_all <- spatial_firing  %>% 
  filter(lm_group_b == "Positive" | lm_group_b == "Negative") 

unclassified_neurons <- spatial_firing  %>% 
  filter(lm_group_b == "Unclassified") 

```

2. Plot scatter plot
```{r}

ggplot() + 
    geom_point(data=subset(position_neurons_all, track_category == "pospos" | track_category == "negneg"),
               aes(x = as.numeric(unlist(asr_b_o_rewarded_fit_slope)), 
                   y = as.numeric(unlist(asr_b_h_rewarded_fit_slope)), 
                   color=factor(unlist(lm_group_b))), alpha=0.8) +
    geom_point(data=subset(position_neurons_all, track_category == "posneg" | track_category == "negpos"),
               aes(x = as.numeric(unlist(asr_b_o_rewarded_fit_slope)), 
                   y = as.numeric(unlist(asr_b_h_rewarded_fit_slope)), 
                   color=factor(unlist(lm_group_b))), shape=2, alpha=0.8) +
    geom_point(data=subset(position_neurons_all, track_category == "posnon" | track_category == "negnon"),
               aes(x = as.numeric(unlist(asr_b_o_rewarded_fit_slope)), 
                   y = as.numeric(unlist(asr_b_h_rewarded_fit_slope)), 
                   color=factor(unlist(lm_group_b))), shape=3, alpha=0.8) +  
    geom_point(data=unclassified_neurons,
               aes(x = as.numeric(unlist(asr_b_o_rewarded_fit_slope)), 
                   y = as.numeric(unlist(asr_b_h_rewarded_fit_slope)), 
                   color=factor(unlist(lm_group_b))), shape=4, alpha=0.8) +     
    coord_cartesian(ylim = c(-.45,.61), xlim = c(-.45,.45)) +
    geom_abline(intercept = 0, slope = 1, colour = "grey", linetype = "dashed") +
    geom_abline(intercept = 0, slope = -1, colour = "grey", linetype = "dashed") +
    xlab("Outbound slope") +
    ylab("Homebound slope") +
    theme_classic() +
    scale_color_manual(values=c("violetred2", "chartreuse3", "grey81")) +
    theme(axis.text.x = element_text(size=18),
          axis.text.y = element_text(size=18),
          legend.position="bottom", 
          legend.title = element_blank(),
          text = element_text(size=17), 
          legend.text=element_text(size=16), 
          axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) 

if (save_figures == 1) {
 ggsave(file = "plots/slope_comparison_reset.png", width = 4, height = 4) 
}
```


### ------------------------------------------------------------------------------------------ ### 

## Plot population rates 

### ------------------------------------------------------------------------------------------ ### 


Now we want to plot population rate across whole track for diff groups so we can visualise the average firing rate

groups are as follows :

outbound homebound  reset
    +       +         n
    +       +         y
    +       -         -
    +      non        -
    -       +         -
    -       -         n
    -       -         y
    -      non        -
    
    

1. make tibble with average firing rates and classifications : 
```{r}
bin = 200
df <- tibble(session_id = rep(spatial_firing$session_id, each=bin),
             cluster = rep(as.character(spatial_firing$cluster_id), each=bin),
             Position = rep(1:bin, times=nrow(spatial_firing)), 
             Rates = unlist(spatial_firing$normalised_rates), 
             Outbound_beaconed = rep(spatial_firing$lm_group_b, each=bin), 
             Homebound_beaconed = rep(spatial_firing$lm_group_b_h, each=bin))

```


Function to plot mean and SEM of firing rate as a function of position.
```{r}
mean_SEM_plots <- function(df, colour1 = "blue"){
  cell_no <- ncol(df)
  df <- df %>%
    dplyr::summarise(mean_r = mean(Rates), sem_r = std.error(Rates)) %>%
    mutate(Position = rep(-29.5:169.5))

  ggplot(data=df) +
  annotate("rect", xmin=-30, xmax=0, ymin=-1.5,ymax=Inf, alpha=0.2, fill="Grey60") +
  annotate("rect", xmin=140, xmax=170, ymin=-1.5,ymax=Inf, alpha=0.2, fill="Grey60") +
  annotate("rect", xmin=60, xmax=80, ymin=-1.5,ymax=Inf, alpha=0.2, fill="Chartreuse4") +
  geom_ribbon(aes(x=Position, y=mean_r, ymin = mean_r - sem_r, ymax = mean_r + sem_r), fill = colour1, alpha=0.2) +
  geom_line(aes(y=mean_r, x=Position), color = colour1) +
  theme_classic() +
  scale_x_continuous(breaks=seq(-30,170,100), expand = c(0, 0)) +
  #annotate("text", x = 140, y=7, label = paste0("n = ", str(cell_no)), size=8) +
  #geom_text(aes(x = 140, y= 6, label = paste0("n = ", str(cell_no))), vjust = "inward", hjust = "inward")
  #scale_y_continuous(breaks=seq(5,50,10), expand = c(0, 0)) +
  labs(y = "Z-scored firing rate", x = "Position") +
  theme(axis.text.x = element_text(size=18),
        axis.text.y = element_text(size=18),
        legend.title = element_blank(),
        text = element_text(size=18),
        plot.margin = margin(21, 25, 5, 20))
}

```



3. Subset data by group then average rates for plotting          **Negative Negative**
```{r}
df_neg_neg <- df %>%
  subset(Outbound_beaconed == "Negative" & Homebound_beaconed == "Negative") %>%
  group_by(Position)
  
mean_SEM_plots(df_neg_neg, colour1 = "black")

if (save_figures == 1) {
 ggsave(file = "plots/negneg_mean_Hz.png",  width = 3.6, height = 2.9) 
}
```




3. Subset data by group then average rates for plotting          **Positive Positive **
```{r}
df_pos_pos <- df %>%
  subset(Outbound_beaconed == "Positive" & Homebound_beaconed == "Positive") %>%
  group_by(Position) 

  
mean_SEM_plots(df_pos_pos, colour1 = "black")


if (save_figures == 1) {
  ggsave(file = "plots/pospos_mean_Hz.png", width = 3.6, height = 2.9) 
}
```


3. Subset data by group then average rates for plotting          **Positive Negative**
```{r}
df_pos_neg <- df %>%
  subset(Outbound_beaconed == "Positive" & Homebound_beaconed == "Negative") %>%
  group_by(Position)


mean_SEM_plots(df_pos_neg, colour1 = "black")

if (save_figures == 1) {
  ggsave(file = "plots/posneg_mean.png", width = 3.6, height = 2.9)
}
```



3. Subset data by group then average rates for plotting          **Positive Negative**
```{r}
df_neg_pos <- df %>%
  subset(Outbound_beaconed == "Negative" & Homebound_beaconed == "Positive") %>%
  group_by(Position)


mean_SEM_plots(df_neg_pos, colour1 = "black")

if (save_figures == 1) {
  ggsave(file = "plots/negpos_mean.png", width = 3.6, height = 2.9)
}
```


3. Subset data by group then average rates for plotting          **Positive Unclassified**
```{r}
df_pos_pi <- df %>%
  subset(Outbound_beaconed == "Positive" & Homebound_beaconed == "Unclassified") %>%
  group_by(Position)


mean_SEM_plots(df_pos_pi, colour1 = "black")

if (save_figures == 1) {
  ggsave(file = "plots/posnon_mean.png", width = 3.6, height = 2.9)
}
```

3. Subset data by group then average rates for plotting          **Negative Unclassified**
```{r}
df_pos_pi <- df %>%
  subset(Outbound_beaconed == "Negative" & Homebound_beaconed == "Unclassified") %>%
  group_by(Position) 

mean_SEM_plots(df_pos_pi, colour1 = "black")

if (save_figures == 1) {
  ggsave(file = "plots/negnon_mean.png", width = 3.6, height = 2.9)
}
```
# get numbers for the plots
```{r}
num_pospos <-spatial_firing %>% filter(track_category_numeric == 1)
num_posneg <-spatial_firing %>% filter(track_category_numeric == 2)
num_posnon <-spatial_firing %>% filter(track_category_numeric == 3)
num_negneg <-spatial_firing %>% filter(track_category_numeric == 4)
num_negpos <-spatial_firing %>% filter(track_category_numeric == 5)
num_negnon <-spatial_firing %>% filter(track_category_numeric == 6)
```


### ----------------------------------------------------------------------------------------- ###


# Plot heat map of firing rate across location for all neurons

First, reorder the dataframe with ramps according to slope.
_For start ramps, steepest slope should be negative - thus will have the highest cluster id_
```{r}

pospos <-spatial_firing %>% filter(track_category_numeric == 1)
posneg <-spatial_firing %>% filter(track_category_numeric == 2)
posnon <-spatial_firing %>% filter(track_category_numeric == 3, mean_firing_rate > 1)
negneg <-spatial_firing %>% filter(track_category_numeric == 4)
negpos <-spatial_firing %>% filter(track_category_numeric == 5)
negnon <-spatial_firing %>% filter(track_category_numeric == 6)

pospos<-pospos[order(-rank(pospos$asr_b_o_rewarded_fit_slope)),decreasing = TRUE]
posneg<-posneg[order(-rank(posneg$asr_b_o_rewarded_fit_slope)),decreasing = TRUE]
posnon<-posnon[order(-rank(posnon$asr_b_o_rewarded_fit_slope)),decreasing = TRUE]
negneg<-negneg[order(negneg$asr_b_o_rewarded_fit_slope),decreasing = TRUE]
negpos<-negpos[order(negpos$asr_b_o_rewarded_fit_slope),decreasing = TRUE]
negnon<-negnon[order(negnon$asr_b_o_rewarded_fit_slope),decreasing = TRUE]

#start_ramps <- rbind(pospos,posneg,posnon,negneg,negpos,negnon)
start_ramps<-spatial_firing[order(unlist(spatial_firing$track_category_numeric),spatial_firing$asr_b_o_rewarded_fit_slope),]
start_ramps<-start_ramps %>% filter(track_category_numeric != 0)
start_ramp_number = nrow(start_ramps)
new_cluster_id = seq(from = 1, to = start_ramp_number, by = 1)
start_ramps <- cbind(start_ramps, new_cluster_id)
```

Then, scale firing rate for all neurons

1. make function to load rates and normalise
2. Run on dataframe 
```{r}
normalise_rates_outbound <- function(df){
  df <- tibble(Rates = unlist(df), Position = rep(1:200))
  df <- df %>%
    filter(Position >=30, Position <= 170)
  x <- normalit(df$Rates)
  return(x)
}

start_ramps <- start_ramps %>%
  mutate(normalised_rates_o = map(Rates_averaged_rewarded_b, normalise_rates_outbound))
```

Add position to normalised rates for plotting
```{r}
add_position <- function(df) {
  df <- tibble(Rates = unlist(df), Position = rep(31:171))
}

start_ramps <- start_ramps %>%
  mutate(normalised_rates_o = map(normalised_rates_o, add_position)) 

```

Extract columns (normalised rates) for plotting into a tibble
```{r}
concat_firing_start <- unnest(select(start_ramps, new_cluster_id, normalised_rates_o))
```

Now the firing rates have been normalised and the data in the right format we want to make annotations for the heatmap

First, extract ramp score from the dataframe for annotating heatmap
_since its a list of three (outbound/homebound/all) we extract the first one_
```{r}
start_ramps <- start_ramps %>%
  mutate(start_ramp_score = map(ramp_score, ~.x[1]))
  
```

Put ramp scores alongisde lm results and brain region classifier in tibble for annotating heatmap
```{r}
ramp_result <- tibble(ramp_score = as.numeric(start_ramps$start_ramp_score))
brain_region <- tibble(region = as.character(start_ramps$brain_region))
lm_result <- tibble(result = as.character(start_ramps$lm_group_b))
lm_result_homebound <- tibble(result_homebound = as.character(start_ramps$lm_group_b_h))
track_result <- tibble(track_cat = as.numeric(start_ramps$track_category_numeric))
cluster_result <- tibble(result = as.character(start_ramps$new_cluster_id))
```

Now we can plot the heatmap with annotations using pheatmap
```{r}
library(viridis)
#convert data to wide format
wide_DF <- concat_firing_start %>% spread(Position, Rates)

#remove unused column
wide_DF <- subset(wide_DF, select=-c(new_cluster_id))

#rownames(wide_DF) <- seq(length=nrow(wide_DF))
# Generte data (modified the mydf slightly)
rownames(wide_DF) <- paste("neuron", 1:max(start_ramps$new_cluster_id), sep="_")

# data for annotation rows in seperate dataframe
mydf <- data.frame(row.names = paste("neuron", 1:max(start_ramps$new_cluster_id), sep="_"), region = brain_region, ramp_score=ramp_result, track_catagory=track_result)
#mydf <- data.frame(row.names = paste("neuron", 1:max(start_ramps$new_cluster_id), sep="_"), region = brain_region, track_catagory=track_result)

# change the color of annotation to what you want: (eg: "navy", "darkgreen")
Var1        <- c("violetred2", "black", "chartreuse3")
names(Var1) <- c("Negative", "Unclassified", "Positive")

Var2        <- c("coral2", "deepskyblue2", "blueviolet" , "grey29")
names(Var2) <- c("PS", "RH", "MEC", "V1")

#Var3        <- c("violetred2", "black", "chartreuse3")
#names(Var3) <- c("Negative", "Unclassified", "Positive")


anno_col <- list(region = Var2, ramp_score = brewer.pal(15,"RdBu"), track_cat = viridis(7))
#anno_col <- list(track_cat = viridis(7))
#anno_col <- list(region = Var2, track_cat = viridis(7))

myheatmap<-pheatmap(wide_DF,cluster_cols = F, cluster_rows = F, annotation_row = mydf, annotation_colors = anno_col, show_rownames = F, show_colnames = F )

```

Save the heatmap (bit of a nightmare here...)
```{r}
save_pheatmap_png <- function(x, filename, width=1300, height=2500, res = 250) {
  png(filename, width = width, height = height, res = res)
  grid::grid.newpage()
  grid::grid.draw(x$gtable)
  dev.off()
}

if (save_figures == 1) {
  save_pheatmap_png(myheatmap, "plots/my_heatmap_all_update.png")
}
```




### ----------------------------------------------------------------------------------------- ###


# Plot ramp scores for high and low firing rate neurons
First, extract ramp score from the dataframe for annotating heatmap
_since its a list of three (outbound/homebound/all) we extract the first one_
```{r}
spatial_firing <- spatial_firing %>%
  mutate(start_ramp_score = map(ramp_score, ~.x[1]))
  
```


```{r}
position_neurons_all <- spatial_firing  %>% 
  #filter(final_model_o_b == "P" | final_model_o_b == "PS" | final_model_o_b == "PA" | final_model_o_b == "PSA")  %>% 
  filter(lm_group_b == "Positive" | lm_group_b == "Negative") 

unclassified_neurons_all <- spatial_firing  %>% 
  #filter(final_model_o_b != "P" & final_model_o_b != "PS" & final_model_o_b != "PA" & final_model_o_b != "PSA")  %>% 
  filter(lm_group_b == "Unclassified") 

```

2. Plot scatter plot
```{r}

ggplot() + 
    geom_point(data=spatial_firing,
               aes(x = as.numeric(unlist(mean_firing_rate)), 
                   y = as.numeric(unlist(start_ramp_score)),
                   color=as.factor(unlist(lm_group_b))), alpha=0.8) +
    ylab("Ramp score (0 - 60 cm)") +
    xlab("Mean firing rate (Hz)") +
    theme_classic() +
    scale_color_manual(values=c( "violetred2", "chartreuse3", "grey32")) +
    theme(axis.text.x = element_text(size=18),
          axis.text.y = element_text(size=18),
          legend.position="bottom", 
          legend.title = element_blank(),
          text = element_text(size=17), 
          legend.text=element_text(size=16), 
          axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) 

if (save_figures == 1) {
 ggsave(file = "plots/rampscore_comparison_FR.png", width = 4, height = 4) 
}
```

2. Plot scatter plot
```{r}

ggplot() + 
    geom_point(data=unclassified_neurons_all,
               aes(x = as.numeric(unlist(mean_firing_rate)), 
                   y = as.numeric(unlist(asr_b_o_rewarded_fit_slope)),
                   color="grey32"), alpha=0.8) +
    geom_point(data=subset(position_neurons_all, start_ramp_score > 0),
               aes(x = as.numeric(unlist(mean_firing_rate)), 
                   y = as.numeric(unlist(start_ramp_score)),
                   color=as.factor(unlist(lm_group_b))), alpha=0.8) +
    #coord_cartesian(ylim = c(-.45,.61), xlim = c(-.45,.45)) +
    ylab("Ramp score (0 - 60 cm)") +
    xlab("Mean firing rate (Hz)") +
    theme_classic() +
    scale_color_manual(values=c("grey32", "chartreuse3","chartreuse3")) +
    theme(axis.text.x = element_text(size=18),
          axis.text.y = element_text(size=18),
          legend.position="bottom", 
          legend.title = element_blank(),
          text = element_text(size=17), 
          legend.text=element_text(size=16), 
          axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) 

if (save_figures == 1) {
 ggsave(file = "plots/rampscore_comparison_FR_positive.png", width = 4, height = 4) 
}
```


```{r}
position_neurons_all <- spatial_firing  %>% 
  #filter(final_model_o_b == "P" | final_model_o_b == "PS" | final_model_o_b == "PA" | final_model_o_b == "PSA")  %>% 
  filter(lm_group_b == "Positive" | lm_group_b == "Negative") 

unclassified_neurons_all <- spatial_firing  %>% 
  #filter(final_model_o_b != "P" & final_model_o_b != "PS" & final_model_o_b != "PA" & final_model_o_b != "PSA")  %>% 
  filter(lm_group_b == "Unclassified") 

```

2. Plot scatter plot
```{r}

ggplot() + 
    geom_point(data=spatial_firing,
               aes(x = as.numeric(unlist(mean_firing_rate)), 
                   y = as.numeric(unlist(asr_b_o_rewarded_fit_slope)),
                   color=factor(unlist(lm_group_b))), alpha=0.8) +
    #coord_cartesian(ylim = c(-.45,.61), xlim = c(-.45,.45)) +
    #geom_abline(intercept = 0, slope = 1, colour = "grey", linetype = "dashed") +
    #geom_abline(intercept = 0, slope = -1, colour = "grey", linetype = "dashed") +
    ylab("Slope (0 - 60 cm)") +
    xlab("Mean firing rate (Hz)") +
    theme_classic() +
    scale_color_manual(values=c("violetred2", "chartreuse3", "grey32")) +
    theme(axis.text.x = element_text(size=18),
          axis.text.y = element_text(size=18),
          legend.position="bottom", 
          legend.title = element_blank(),
          text = element_text(size=17), 
          legend.text=element_text(size=16), 
          axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) 

if (save_figures == 1) {
 ggsave(file = "plots/Slope_comparison_FR.png", width = 4, height = 4) 
}
```

2. Plot scatter plot
```{r}

ggplot() + 
    geom_point(data=unclassified_neurons_all,
               aes(x = as.numeric(unlist(mean_firing_rate)), 
                   y = as.numeric(unlist(asr_b_o_rewarded_fit_slope)),
                   color=factor(unlist(lm_group_b))), alpha=0.8) +
    geom_point(data=subset(position_neurons_all, lm_group_b == "Positive"),
               aes(x = as.numeric(unlist(mean_firing_rate)), 
                   y = as.numeric(unlist(asr_b_o_rewarded_fit_slope)),
                   color=factor(unlist(lm_group_b))), alpha=0.8) +
    ylab("Slope (0 - 60 cm)") +
    xlab("Mean firing rate (Hz)") +
    theme_classic() +
    scale_color_manual(values=c( "chartreuse3", "grey32")) +
    theme(axis.text.x = element_text(size=18),
          axis.text.y = element_text(size=18),
          legend.position="bottom", 
          legend.title = element_blank(),
          text = element_text(size=17), 
          legend.text=element_text(size=16), 
          axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) 

if (save_figures == 1) {
 ggsave(file = "plots/Slope_comparison_FR_positive.png", width = 4, height = 4) 
}
```



## Find average and STD number of rewarded sessions in the data

1. select columns we want
2. find distinct columns (this is because multiple days have many cells, an we only want unique days so the mean is accurate)
3. find mean number of rewarded trials and std of rewarded trials

```{r}
df <- spatial_firing %>%
  select(Day, Mouse, cohort, max_trial_number, number_of_rewards) %>%
  distinct() %>%
  dplyr::summarise(mean_r = mean(as.numeric(number_of_rewards), na.rm =TRUE), sem_r = std.error(as.numeric(number_of_rewards))) 

```

