---
title: "Prelim_Analysis_0100"
author: "Sarah Tennant"
date: "07/04/2020"
output: html_document
---

## Analysis of neurons recorded from the medial entorhinal cortex during virtual navigation

The aim of this analysis is to identify all ramp cells within a specified dataset (all mice or all days for one mouse) and perform analysis to investigate their firing properties. 
1. Identify cells that represent location by ramping their firing rate using LM modeling 
2. Subset data by model fit (r2 value)
3. Compare firing rates of cells in this group


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import packages

```{r}
library(tidyverse)
library(broom)
library(lme4)
library(ggplot2)
library(ggExtra)
library(ggthemes)
library(scales)
library(dplyr)
library(tidyr)
library(Hmisc)
library(Metrics)
library(plotrix)
#library(plyr)
#library("plot3D")
#library(NetworkD3)
```


## Import functions

```{r}
source("Functions.R")
source("Functions_Outbound_LMER.R")
```


## Load the data

1. Set up the python environment. 
This is so we can call a python script from R that loads the pickled dataframes and sends it back to the R workspace. 
The python environment needs to be >v.3 as 2.7 (system python) doesnt have Pandas package which is needed to open dataframes

```{r}

require(reticulate) # package that allows R to call python code
Sys.setenv(RETICULATE_PYTHON = "/usr/local/Cellar/python3/3.7.4_1/Frameworks/Python.framework/Versions/3.7/bin/python3.7") 

```

2. Load dataframe for all mice and days (all curated cells from one animal/multiple animals)

```{r}
dataframe_to_load <- "data/Alldays_cohort_1_1.pkl" # name of the pickled dataframe want to load 
source_python("pickle_reader.py") # run python script which loads the dataframes - should be in working directory
spatial_firing <- read_pickle_file(file.path(dataframe_to_load)) # function to call in the python code

```

OR 2. load RDa file 

```{r}
spatial_firing <- readRDS(file="df_final.Rda")
```

```{r}
saveRDS(spatial_firing, file="df_final.Rda")
```


### ----------------------------------------------------------------------------------------- ###

## Average firing rate (for LM modelling)


The linear model uses firing rate data binned in space. For this we want to load average firing rate over trials from the data frame for each cluster. 
- Map over "Rates_averaged" column and extract averaged rates
- Add position for each point ( data is binned into 200, 1 cm bins )
- Insert result back into dataframe
- Do this for beaconed, nonbeaconed and probe trials
- Do this for shuffled spike rate (beaconed)

1. Write function to add position
```{r}
add_position <- function(df) {
  df <- tibble(Rates = unlist(df)*5, Position = rep(1:200))
}
```

2. Run on dataframe 
```{r}
spatial_firing <- spatial_firing %>%
  mutate(asr_b = map(Rates_averaged, add_position)) %>%
  mutate(asr_nb = map(Rates_averaged_nb, add_position)) %>%
  mutate(asr_p = map(Rates_averaged_p, add_position)) %>%
  mutate(shuff_asr_b = map(Shuffled_Rates_averaged, add_position)) %>%
  mutate(shuff_asr_nb = map(Shuffled_Rates_averaged, add_position)) %>%
  mutate(shuff_asr_p = map(Shuffled_Rates_averaged, add_position))

```



### ----------------------------------------------------------------------------------------- ###

# Remove NA's and clusters with no data on probe trials

_note cell/n number prior to this step is 778, after is 697_
First make function to sum rates column
Then remove all columns where sum of rates = nan 
_Note : this prevents an error during linear modelling where there is only NA cases which cannot be handled_

1. Write function to sum rates
```{r}
sum_rates <- function(df){
  if(all(is.na(df))) 
    return(0)
  x = sum(as.numeric(df$Rates), na.rm=TRUE)
}
```

2. Run on dataframe 
```{r}

spatial_firing_filt <- spatial_firing %>% 
  mutate(asr_b_sum = map(asr_b, sum_rates)) %>% 
  mutate(asr_nb_sum = map(asr_nb, sum_rates)) %>% 
  mutate(asr_p_sum = map(asr_p, sum_rates)) %>% 
  mutate(shuff_asr_b_sum = map(shuff_asr_b, sum_rates)) %>% 
  mutate(shuff_asr_nb_sum = map(shuff_asr_nb, sum_rates)) %>% 
  mutate(shuff_asr_p_sum = map(shuff_asr_p, sum_rates))

```

3. Remove NA's and clusters with no data on probe trials
```{r}
spatial_firing <- spatial_firing_filt %>% 
  filter(asr_b_sum != 0 & shuff_asr_b_sum != 0 & asr_nb_sum != 0 & shuff_asr_nb_sum != 0 & asr_p_sum != 0 & shuff_asr_p_sum != 0)
```


### ----------------------------------------------------------------------------------------- ###


## Run linear model on outbound region of track

Next we want to perform LM on each cluster to analyse firing rate verses location.
- Make a new columns in dataframe for output of linear model
- Fit the model from average rates versus location for each cluster
- Then put the results into new columns of the dataframe

Do this for each trial type: beaconed, non-beaconed and probe:
Do the same as above but with the start of the track.

1. Make functions for linear modelling
```{r}
lm_analysis <- function(df, spike_rate_col, startbin = 30, endbin = 90) {
  spike_rate_col <- enquo(spike_rate_col)
  out_name <- sym(paste0(quo_name(spike_rate_col)))
  sr_unnest_name <- sym(paste0(quo_name(spike_rate_col), "_unnest"))
  fit_name <- sym(paste0(quo_name(out_name), "_fit"))
  glance_name <- sym(paste0(quo_name(out_name), "_glance"))
  r2_name <- sym(paste0(quo_name(out_name), "_r2_o"))
  Pval_name <- sym(paste0(quo_name(out_name), "_Pval_o"))
  slope_name <- sym(paste0(quo_name(out_name), "_slope_o"))
  intercept_name <- sym(paste0(quo_name(out_name), "_intercept_o"))
  df <- df %>%
    mutate(!!fit_name := map(!!spike_rate_col, bins=c(startbin:endbin), lm_helper),
           !!glance_name := map(!!fit_name, glance),
           !!r2_name := map_dbl(!!glance_name, ~.$r.squared),
           !!Pval_name := map_dbl(!!glance_name, ~.$p.value),
           !!slope_name := map_dbl(!!fit_name, ~.$coefficients[2]),
           !!intercept_name := map_dbl(!!fit_name, ~.$coefficients[1]))
}
```

2. Run on dataframe 

```{r}
spatial_firing <- spatial_firing %>%
  lm_analysis(asr_b, 30, 90) %>%
  lm_analysis(asr_nb, 30, 90) %>%
  lm_analysis(asr_p, 30, 90) %>%
  lm_analysis(shuff_asr_b, 30, 90) %>%
  lm_analysis(shuff_asr_nb, 30, 90) %>%
  lm_analysis(shuff_asr_p, 30, 90)
```


### ----------------------------------------------------------------------------------------- ###


## Identification of ramp cells in dataset (Beaconed trials)

Here we do this by finding the tails of the shuffled data

1. load slope and r2 from shuffled datasets for all neurons

```{r}
slopes <- as.numeric(na.omit(spatial_firing$shuff_asr_b_slope_o))
r2 <- as.numeric(na.omit(spatial_firing$shuff_asr_b_r2_o))
```

2. find the 95% and 5% percentiles of the shuffled data

```{r}
min_slope_o <- quantile(slopes, c(.05, .95)) [[1]][1]
max_slope_o <- quantile(slopes, c(.05, .95)) [[2]][1]
max_r2_o <- quantile(r2, c(.05, .95)) [[2]][1]
min_r2_o <- quantile(r2, c(.05, .95)) [[1]][1]
```


## Mark neurons by lm result in outbound region

```{r}

spatial_firing <- spatial_firing %>%
  mutate(lm_result_o_b = pmap(list(asr_b_Pval_o, asr_b_r2_o, asr_b_slope_o,max_r2_o, max_slope_o, min_slope_o), select_final_lm_result))  %>%
  mutate(lm_result_o_nb = pmap(list(asr_nb_Pval_o, asr_nb_r2_o, asr_nb_slope_o,max_r2_o, max_slope_o, min_slope_o), select_final_lm_result))  %>%
  mutate(lm_result_o_p = pmap(list(asr_p_Pval_o, asr_p_r2_o, asr_p_slope_o,max_r2_o, max_slope_o, min_slope_o), select_final_lm_result))

```



```{r}

spatial_firing <- spatial_firing %>%
  mutate(lm_result_o_rewarded = pmap(list(asr_b_rewarded_Pval_o, asr_b_rewarded_r2_o, asr_b_rewarded_slope_o,max_r2_o, max_slope_o, min_slope_o), select_final_lm_result))

```



### ----------------------------------------------------------------------------------------- ###


```{r}
start_ramps <- spatial_firing %>%
  filter(asr_b_r2_o > max_r2_o)
```


First, reorder the dataframe with ramps according to slope.
_For start ramps, steepest slope should be negative - thus will have the highest cluster id_

```{r}
start_ramps<-start_ramps[order(start_ramps$asr_b_slope_o),]
start_ramp_number = nrow(start_ramps)
new_cluster_id = seq(from = 1, to = start_ramp_number, by = 1)
start_ramps <- cbind(start_ramps, new_cluster_id)
```
Then we want to look at the distribution of these firing proeprty variables in our ramp cell dataset. 
_to examine only ramp/distance cells we are looking only at neurons that had slope > 0.15 from using a GLM on firing rate and distance_

Prep data:
1. Filter dataset for slope to get only ramp cells
2. Create marker for whether is start or end of track firing cells
3. Concatenate frames so all ramps are in one frame

```{r}
to_reward_ramps <- subset(start_ramps, lm_result_o_b == "Positive")
ramp_id=rep("to_reward", times= nrow(to_reward_ramps))
binary_ramp_id = rep(4, times= nrow(to_reward_ramps))
to_reward_ramps <- cbind(to_reward_ramps, ramp_id, binary_ramp_id)

start_ramps <- subset(start_ramps, lm_result_o_b == "Negative")
ramp_id=rep("start", times= nrow(start_ramps))
binary_ramp_id = rep(1, times= nrow(start_ramps))
start_ramps <- cbind(start_ramps, ramp_id, binary_ramp_id)

outbound_ramps <- bind_rows(start_ramps, to_reward_ramps)

```




### ----------------------------------------------------------------------------------------- ###



### Plot LM results for outbound region

1. make two tibbles with data
- first tibble contains all data
- second tibble contains only ramp data as identified by lm

```{r}
lm_results <- return_b_shuffle_lm_results(spatial_firing)

lm_results_ramps <- tibble(Ramp_type = c(as.character(start_ramps$ramp_id), as.character(to_reward_ramps$ramp_id)),
    Slopes = c(start_ramps$asr_b_slope_o, to_reward_ramps$asr_b_slope_o), 
    r2 = c(start_ramps$asr_b_r2_o, to_reward_ramps$asr_b_r2_o), 
    id = c(start_ramps$cluster_id, to_reward_ramps$cluster_id))
```

2. Plot results, color coded by ramp type

```{r}


lm_plot_start <- ggplot(data=lm_results_ramps, aes(x = Slopes, y = r2, color=factor(Ramp_type))) + 
    coord_cartesian(xlim = c(-0.65,0.65), ylim = c(0,1)) +
    geom_point(alpha=.4) +
    geom_point(data=lm_results, aes(x = Slopes, y = r2, color=factor(Trial_type))) +
    geom_point(data=lm_results_ramps, aes(x = Slopes, y = r2, color=factor(Ramp_type)),alpha=.4) +
    xlab("\nslope") +
    ylab("R2") +
    theme_classic() +
    scale_color_manual(values=c("grey82", "grey32", "violetred2", "chartreuse3")) +
    theme(axis.text.x = element_text(size=12),
          axis.text.y = element_text(size=12),
          legend.position="bottom", 
          legend.title = element_blank(),
          text = element_text(size=12), 
          legend.text=element_text(size=12), 
          axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) 

lm_plot_start <- lm_plot_start + geom_vline(xintercept = min_slope_o , linetype="dotted", 
                color = "blue", size=.6)
lm_plot_start <- lm_plot_start + geom_vline(xintercept = max_slope_o, linetype="dotted", 
                color = "blue", size=.6)
lm_plot_start <- lm_plot_start + geom_hline(yintercept = max_r2_o, linetype="dotted", 
                color = "red", size=.6)
lm_plot_start <- lm_plot_start + geom_hline(yintercept = min_r2_o, linetype="dotted", 
                color = "red", size=.6)

ggsave(file = "plots/shuff_lm1.png", width = 4, height = 5)

```


# find and plot proportions for ramp types in dataset

```{r}
# positive homebound slopes
spatial <-subset(spatial_firing, lm_result_o_b != "None")
start <- nrow(subset(spatial, lm_result_o_b == "Negative"))/nrow(spatial_firing)*100
reward <- nrow(subset(spatial, lm_result_o_b == "Positive"))/nrow(spatial_firing)*100
nonslope <- nrow(subset(spatial, lm_result_o_b == "NoSlope"))/nrow(spatial_firing)*100

proportions_mixed_ramps <- tibble(perc=c(start, reward, nonslope), ramp_id= c("Start", "ToReward", "NoSlope"),ramp_type = c("Start", "ToReward", "NoSlope"))

```

```{r}
ggplot(proportions_mixed_ramps, aes(x= ramp_type, y = perc, fill=factor(ramp_id))) +
  geom_bar(stat="identity",width = 0.9, alpha = .4) +
  labs(y = "Percent") +
  scale_fill_manual(values=c("grey62", "violetred2", "chartreuse3")) +
  theme_classic() +
  theme(axis.text.x = element_text(size=18),
        axis.text.y = element_text(size=18),
        legend.position="bottom", 
        legend.title = element_blank(),
        text = element_text(size=18), 
        legend.text=element_text(size=18), 
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) +

ggsave(file = "plots/LMStart_cellproportions.png", width = 3, height = 6)

```

3. get numbers of cells for each lm group (positive/negative/unclassified)
```{r}
start <- nrow(subset(spatial, lm_result_o_b == "Negative"))
reward <- nrow(subset(spatial, lm_result_o_b == "Positive"))
nonslope <- nrow(subset(spatial, lm_result_o_b == "NoSlope"))

```



### ----------------------------------------------------------------------------------------- ###

## Run mixed effect model which examines contribution of speed, acceleration and position on firing rate

1. Functions to perform linear mixed effect model


2. Run on all cells 
```{r}
spatial_firing <- spatial_firing  %>%
  mutate(o_pos_b = map(spikes_in_time, car_pos_b)) %>%
  mutate(o_speed_b = map(spikes_in_time, car_speed_b)) %>%
  mutate(o_accel_b = map(spikes_in_time, car_accel_b)) %>%
  mutate(o_pos_nb = map(spikes_in_time, car_pos_nb)) %>%
  mutate(o_speed_nb = map(spikes_in_time, car_speed_nb)) %>%
  mutate(o_accel_nb = map(spikes_in_time, car_accel_nb)) %>%
  mutate(o_pos_p = map(spikes_in_time, car_pos_p)) %>%
  mutate(o_speed_p = map(spikes_in_time, car_speed_p)) %>%
  mutate(o_accel_p = map(spikes_in_time, car_accel_p))
```


### ----------------------------------------------------------------------------------------- ###


## Select best model 

1. Write function to perform model selection
```{r}

model_comparison <- function(null_pos, null_speed, null_accel){
  pval <- 0.01
  if( is.na(null_pos) & is.na(null_accel)) {
    return( "None" )
  
  } else if( null_pos < pval & null_accel > pval & null_speed > pval) {
    return( "P" )
    
  } else if( null_pos > pval & null_accel > pval & null_speed < pval) {
    return( "S" ) 
    
  } else if( null_pos > pval & null_accel < pval & null_speed > pval) {
    return( "A" )
    
  } else if( null_pos < pval & null_accel > pval & null_speed < pval) {
    return("PS")
    
  } else if( null_pos < pval & null_accel < pval & null_speed > pval) {
    return( "PA" )
        
  } else if( null_pos > pval & null_accel < pval & null_speed < pval) {
    return("SA")

  } else if( null_pos < pval & null_accel < pval & null_speed < pval) {
    return("PSA")
    
  } else {
    return("None")
  }
}

```

2. Run on all cells in dataframe
```{r}
spatial_firing <- spatial_firing  %>%
    mutate(final_model_o_b  = pmap(list(o_pos_b, o_speed_b, o_accel_b), model_comparison)) %>%
    mutate(final_model_o_nb  = pmap(list(o_pos_nb, o_speed_nb, o_accel_nb), model_comparison))  %>%
    mutate(final_model_o_p  = pmap(list(o_pos_p, o_speed_p, o_accel_p), model_comparison))

```




### ----------------------------------------------------------------------------------------- ###


# PLOT HEAT MAPS FOR ALL NEURONS


First, reorder the dataframe with ramps according to slope.
_For start ramps, steepest slope should be negative - thus will have the highest cluster id_

```{r}
start_ramps<-spatial_firing[order(spatial_firing$asr_b_slope_o),]
start_ramp_number = nrow(start_ramps)
new_cluster_id = seq(from = 1, to = start_ramp_number, by = 1)
start_ramps <- cbind(start_ramps, new_cluster_id)
```


Then, scale firing rate for all neurons

1. make function to load rates and normalise
2. Run on dataframe 
```{r}
normalise_rates_outbound <- function(df){
  df <- tibble(Rates = unlist(df), Position = rep(1:200))
  df <- df %>%
    filter(Position >=30, Position <= 90)
  x <- normalit(df$Rates)
  return(x)
}

start_ramps <- start_ramps %>%
  mutate(normalised_rates_o = map(Rates_averaged, normalise_rates_outbound))

```

Add position to normalised rates for plotting
```{r}
add_position <- function(df) {
  df <- tibble(Rates = unlist(df), Position = rep(30:90))
}

start_ramps <- start_ramps %>%
  mutate(normalised_rates_o = map(normalised_rates_o, add_position))

```

Extract columns (normalised rates) for plotting into a tibble
```{r}
concat_firing_start <- unnest(select(na.omit(start_ramps), new_cluster_id, normalised_rates_o))
```


Extract ramp score for annotating heatmap
_since its a list of three (outbound/homebound/all) we extract the first one_
```{r}
extract_ramp_score <- function(df){
  dx <- df[[1]]
  return(dx)
}

start_ramps <- start_ramps %>%
  mutate(start_ramp_score = map(ramp_score, extract_ramp_score))

```

Put ramp scores and lm results in tibble for annotating heatmap
```{r}
# data for annotating
ramp_result <- tibble(ramp_score = as.numeric(start_ramps$start_ramp_score))
lm_result <- tibble(result = as.character(start_ramps$lm_result_o_b))
cluster_result <- tibble(result = as.character(start_ramps$new_cluster_id))
```


Plot heatmap with annotations using pheatmap
```{r}
#library(pheatmap) # import pheatmap if necessary

#convert data to wide format
wide_DF <- concat_firing_start %>% spread(Position, Rates)

# Generte data (modified the mydf slightly)
colnames(wide_DF) <- c("new_cluster_id", rep(30:90, times=1))
rownames(wide_DF) <- paste("neuron", 1:max(new_cluster_id), sep="_")

#remove unused column
name <- "new_cluster_id"
wide_DF <- wide_DF %>% select(-one_of(name))

# data for annotation rows in seperate dataframe
mydf <- data.frame(row.names = paste("neuron", 1:max(new_cluster_id), sep="_"), category = lm_result, ramp = ramp_result)

# change the color of annotation to what you want: (eg: "navy", "darkgreen")
Var1        <- c("violetred2","grey62", "black","chartreuse3")
names(Var1) <- c("Negative", "NoSlope", "None", "Positive")

anno_col <- list(result = Var1, ramp_score = brewer.pal(11,"RdBu"))


myheatmap<-pheatmap(wide_DF,cluster_cols = F, cluster_rows = F , annotation_row = mydf, annotation_colors = anno_col, show_rownames = F, show_colnames = F)
```



## test pheatmap

```{r}
# Generate some data
test = matrix(rnorm(200), 20, 10)
test[1:10, seq(1, 10, 2)] = test[1:10, seq(1, 10, 2)] + 3
test[11:20, seq(2, 10, 2)] = test[11:20, seq(2, 10, 2)] + 2
test[15:20, seq(2, 10, 2)] = test[15:20, seq(2, 10, 2)] + 4
colnames(test) = paste("Test", 1:10, sep = "")
rownames(test) = paste("Gene", 1:20, sep = "")
# original figure
pheatmap(test)
# Add annotation as described above, and change the name of annotation
annotation <- data.frame(Var1 = factor(1:10 %% 2 == 0, labels = c("Exp1", "Exp2")))
rownames(annotation) <- colnames(test) # check out the row names of annotation
pheatmap(test, annotation = annotation)

# change the color of annotation to what you want: (eg: "navy", "darkgreen")
Var1        <- c("navy", "darkgreen")
names(Var1) <- c("Exp1", "Exp2")
anno_colors <- list(Var1 = Var1)
pheatmap(test, annotation = annotation, annotation_colors = anno_colors)
```



```{r}
save_pheatmap_png <- function(x, filename, width=1300, height=2500, res = 250) {
  png(filename, width = width, height = height, res = res)
  grid::grid.newpage()
  grid::grid.draw(x$gtable)
  dev.off()
}
 
save_pheatmap_png(myheatmap, "my_heatmap_all.png")
```

### ----------------------------------------------------------------------- ###


# SLOPE COMPARISON BETWEEN OUTBOUND AND HOMEBOUND REGION (MULTICOLOR PLOTS)

Here we want to see whether cells who have steep slopes in the outbound or homebound region are also slopey in the other part of the track. 
In order to do this we will compare slopes in start of track with slopes in end of track.

First, get all the data into format that is plotable. 

```{r}
slope_comparison <- as.tibble(cbind(cluster_id=spatial_firing$cluster_id, 
                          start_p_slope = spatial_firing$asr_p_slope_o,
                          end_p_slope = spatial_firing$asr_p_slope_h,
                          start_p_r2 = spatial_firing$asr_p_r2_o, 
                          end_p_r2 = spatial_firing$asr_p_r2_h, 
                          start_b_slope = spatial_firing$asr_b_slope_o,
                          end_b_slope = spatial_firing$asr_b_slope_h,
                          start_b_r2 = spatial_firing$asr_b_r2_o, 
                          end_b_r2 = spatial_firing$asr_b_r2_h, 
                          lm_result_start = spatial_firing$lm_result_o_b,
                          lm_result_end = spatial_firing$lm_result_h_b,
                          firing_rate = spatial_firing$asr_b))

```


# for probe trials
```{r}
slope_comparison <- as.tibble(cbind(cluster_id=spatial_firing$cluster_id, 
                          start_p_slope = spatial_firing$asr_p_slope_o,
                          end_p_slope = spatial_firing$asr_p_slope_h,
                          start_p_r2 = spatial_firing$asr_p_r2_o, 
                          end_p_r2 = spatial_firing$asr_p_r2_h, 
                          start_b_slope = spatial_firing$asr_p_slope_o,
                          end_b_slope = spatial_firing$asr_p_slope_h,
                          start_b_r2 = spatial_firing$asr_p_r2_o, 
                          end_b_r2 = spatial_firing$asr_p_r2_h, 
                          lm_result_start = spatial_firing$lm_result_o_p,
                          lm_result_end = spatial_firing$lm_result_h_p,
                          firing_rate = spatial_firing$asr_p))

```

Then, subset the data based on LM r-squared value and slope to extract distance encoding cells. 

```{r}
slope_comparison<-as_tibble(slope_comparison)
slope_comparison <- subset(slope_comparison, lm_result_start != "None" | lm_result_end != "None" | lm_result_start != "NoSlope" | lm_result_end != "NoSlope")

```


## Find proportions of cells for each distance type that are in catagory
1. subset cells based on outbound and homebound slope

```{r}
# positive outbound
pos_out <-subset(slope_comparison, lm_result_start == "Positive")
yellow <- nrow(subset(pos_out, lm_result_end == "Positive"))/nrow(slope_comparison)*100
yellow_green <- nrow(subset(pos_out, lm_result_end == "Negative"))/nrow(slope_comparison)*100
yellow_darkgreen <- nrow(subset(pos_out, lm_result_end == "None" | lm_result_end == "NoSlope"))/nrow(slope_comparison)*100

neg_out <-subset(slope_comparison, lm_result_start == "Negative")
green <- nrow(subset(neg_out, lm_result_end == "Negative"))/nrow(slope_comparison)*100
green_yellow <- nrow(subset(neg_out, lm_result_end == "Positive"))/nrow(slope_comparison)*100
darkgreen_yellow <- nrow(subset(neg_out, lm_result_end == "None" | lm_result_end == "NoSlope"))/nrow(slope_comparison)*100


proportions_mixed_ramps <- tibble(perc=c(yellow, yellow_green, yellow_darkgreen, green, green_yellow, darkgreen_yellow), ramp_id= c("Magenta", "Burgunde", "Red", "orange",  "yellow", "green"),ramp_type = c("Magenta", "Burgunde", "Red", "orange",  "yellow", "green"))
```


# plot data

```{r}
level_order <- c("Magenta", "Burgunde", "Red", "orange",  "yellow", "green", "Blue", "purple")
ggplot(proportions_mixed_ramps, aes(x= factor(ramp_type, level = level_order), y = perc, fill=factor(ramp_id, level = level_order))) +
  geom_bar(stat="identity",width = 0.9, alpha = .7) +
  labs(y = "Percent") +
  scale_fill_manual(values=c("deeppink1","red3", "red1", "darkorange1", "darkgoldenrod1", "springgreen3", "steelblue3", "purple1")) +
  theme_classic() +
  theme(axis.text.x = element_text(size=18),
        axis.text.y = element_text(size=18),
        legend.position="bottom", 
        legend.title = element_blank(),
        text = element_text(size=18), 
        legend.text=element_text(size=18), 
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) +

ggsave(file = "plots/ramp_mixedproportions.png", width = 7, height = 6)
```





# subset data into types

```{r}

# positive outbound
pos_out <-subset(slope_comparison, lm_result_start == "Positive")

yellow <- subset(pos_out, lm_result_end == "Positive")
ramp_id=rep("yellow", times= nrow(yellow))
yellow <- cbind(yellow, ramp_id)

yellow_green <- subset(pos_out, lm_result_end == "Negative")
ramp_id=rep("yellow_green", times= nrow(yellow_green))
yellow_green <- cbind(yellow_green, ramp_id)

yellow_darkgreen <- subset(pos_out, lm_result_end == "None" | lm_result_end == "NoSlope")
ramp_id=rep("yellow_darkgreen", times= nrow(yellow_darkgreen))
yellow_darkgreen <- cbind(yellow_darkgreen, ramp_id)

neg_out <-subset(slope_comparison, lm_result_start == "Negative")
green <- subset(neg_out, lm_result_end == "Negative")
ramp_id=rep("green", times= nrow(green))
green <- cbind(green, ramp_id)

green_yellow <- subset(neg_out, lm_result_end == "Positive")
ramp_id=rep("green_yellow", times= nrow(green_yellow))
green_yellow <- cbind(green_yellow, ramp_id)

darkgreen_yellow <- subset(neg_out, lm_result_end == "None" | lm_result_end == "NoSlope")
ramp_id=rep("darkgreen_yellow", times= nrow(darkgreen_yellow))
darkgreen_yellow <- cbind(darkgreen_yellow, ramp_id)


mixed_ramps_concat <- rbind(yellow, yellow_green, yellow_darkgreen, green, green_yellow, darkgreen_yellow)
#mixed_ramps <- mixed_ramps_concat %>% select("start_b_slope", "end_b_slope", "start_nb_slope", "end_nb_slope", "ramp_id")
mixed_ramps <- na.omit(mixed_ramps_concat)
```


# repot comparison of slopes

```{r}
level_order <- c("yellow", "yellow_green", "yellow_darkgreen", "green",  "green_yellow", "darkgreen_yellow")

ggplot(mixed_ramps,aes(x = as.numeric(start_b_slope), y = as.numeric(end_b_slope), color=factor(ramp_id, level=level_order))) + 
    geom_jitter() +
    coord_cartesian(ylim = c(-.6,.6), xlim = c(-.6,.6)) +
    xlab("Outbound slope") +
    ylab("Homebound slope") +
    theme_classic() +
    scale_color_manual(values=c("#FDE725FF","#B4DE2CFF","#6DCD59FF", "#B4DE2CFF","#FDE725FF","#6DCD59FF")) +
    theme(axis.text.x = element_text(size=16),
          axis.text.y = element_text(size=16),
          legend.position="bottom", 
          legend.title = element_blank(),
          text = element_text(size=16), 
          legend.text=element_text(size=16), 
          axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) 
ggsave(file = "plots/slope_comparison_plot2_probe.png", width = 5, height = 5)

```

