---
title: "Preliminary_Analysis"
author: "Sarah Tennant"
date: "27/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### ----------------------------------------------------------------------------------------- ###

### Script runs preliminary analysis, including linear model, on all neurons to detect ramp-like cells

### ----------------------------------------------------------------------------------------- ###


First import packages

```{r}
library(tidyverse)
library(broom)
library(lme4)
library(ggplot2)
library(ggExtra)
library(ggthemes)
library(scales)
library(dplyr)
library(tidyr)
library(Hmisc)
library(Metrics)
library(plotrix)
#library(plyr)
#library("plot3D")
#library(NetworkD3)
```


And import functions

```{r}
source("Functions.R")
source("Functions_Outbound_LMER.R")
```


## Load the data
_note : only run if not ran ConvertPickletoRda.Rmd_

_load from pickle_
1. Set up the python environment. 
This is so we can call a python script from R that loads the pickled dataframes and sends it back to the R workspace. 
The python environment needs to be >v.3 as 2.7 (system python) doesnt have Pandas package which is needed to open dataframes

```{r}

require(reticulate) # package that allows R to call python code
Sys.setenv(RETICULATE_PYTHON = "/usr/local/Cellar/python3/3.7.4_1/Frameworks/Python.framework/Versions/3.7/bin/python3.7") 

```

2. Load dataframe for all mice and days (all curated cells from one animal/multiple animals)

```{r}
dataframe_to_load <- "data/Alldays_cohort_1_1.pkl" # name of the pickled dataframe want to load 
source_python("pickle_reader.py") # run python script which loads the dataframes - should be in working directory
spatial_firing <- read_pickle_file(file.path(dataframe_to_load)) # function to call in the python code

```

_load from RDa_
1. load RDa file 

```{r}
spatial_firing <- readRDS(file="df_final.Rda")

```

2. also resave here if needed (after analysis)
```{r}
saveRDS(spatial_firing, file="df_final.Rda")
```


### ----------------------------------------------------------------------------------------- ###

# Curate data by reward number

1. Make function to sum number of rewards
```{r}
find_reward_number <- function(df) {
  x <- length(df[!is.na(df)])
  return(as.numeric(x))
}
```

2. Run on all neurons
```{r}
spatial_firing <- spatial_firing  %>%
  mutate(number_of_rewards = map(rewarded_locations, find_reward_number))
```

3. Remove sessions with < 30 rewards
```{r}
spatial_firing <- subset(spatial_firing, number_of_rewards >= 30)

```


### ----------------------------------------------------------------------------------------- ###

## Average firing rate (for LM modelling)

The linear model uses firing rate data binned in space. For this we want to load average firing rate over trials from the data frame for each cluster. 
- Map over "Rates_averaged" column and extract averaged rates
- Add position for each point ( data is binned into 200, 1 cm bins )
- Insert result back into dataframe
- Do this for beaconed, nonbeaconed and probe trials
- Do this for shuffled spike rate (beaconed)


_trial by trial_
1. Write function to add position and trial number
```{r}
add_position <- function(df) {
  size_df <- length(as.vector(unlist(df)))
  if(size_df <2) 
    return(tibble(Rates = as.character()))
  df <- tibble(Rates = as.vector(unlist(df)), Position = rep(1:200, times=size_df/200), Trials = rep(1:(size_df/200), each=200))
}
```

2. Run on dataframe : Average trials with reward
```{r}
spatial_firing <- spatial_firing %>%
  mutate(asr_b_rewarded = map(Firing_rate_rewarded_b, add_position)) %>%
  mutate(asr_p_rewarded = map(Firing_rate_rewarded_nb, add_position)) %>%
  mutate(asr_nb_rewarded = map(Firing_rate_rewarded_p, add_position))
  #mutate(shuff_asr_b = map(Shuffled_Rates_averaged, add_position))

```


### ----------------------------------------------------------------------------------------- ###

# Remove NA's and clusters with no data on probe trials
_note : this is to prevent an error when running the LM - temp fix_

1. Write function to sum rates
```{r}
sum_rates <- function(df){
  if(all(is.na(as.numeric(df$Rates))))
    return(0)
  df <- df  %>% subset(Position > 30 & Position <= 90) 
  x = sum(as.numeric(df$Rates), na.rm=TRUE)     
}
```

2. Run on dataframe : sum rates across location for each cluster
```{r}

spatial_firing <- spatial_firing %>% 
  mutate(asr_b_reward_sum = map(asr_b_rewarded, sum_rates)) %>%
  mutate(shuff_reward_sum = map(shuff_asr_b, sum_rates)) %>%
  mutate(asr_p_reward_sum = map(asr_p_rewarded, sum_rates)) %>% 
  #mutate(asr_nb_reward_sum = map(asr_nb_rewarded, sum_rates))
  #mutate(asr_fail_sum = map(asr_b_failed, sum_rates)) 

```

3. Remove NA's and clusters with no data on probe trials
```{r}
spatial_firing <- spatial_firing %>% 
  filter(asr_b_reward_sum > 0 )
#& asr_p_reward_sum > 0 & asr_nb_reward_sum > 0 
```


### ----------------------------------------------------------------------------------------- ###

# Run simple linear model 
1. Function to run simple lm (Rates ~ Position)
```{r}
lm_helper <- function(df, bins){
  if(all(is.na(df))) 
    return(0)
  df <- df  %>% subset(Position >= 30 & Position <= 90) 
  df_mod <- lm(Rates ~ Position, data = df[30:90], na.action=na.exclude)
}
```

# Average over trials before putting in LM _not current method?_
```{r}
lm_helper <- function(df, bins){
  if(all(is.na(df))) 
    return(0)
  df <- df  %>% subset(Position > 30 & Position <= 90) %>%  
    group_by(Position) %>%
    summarise(Rates = mean(Rates, na.rm = TRUE))  %>% 
    mutate(Position = c(31:90))
  df_mod <- lm(Rates ~ Position, data = df, na.action=na.exclude)
}
```

2. Function to extract data from lm
```{r}
lm_analysis <- function(df, spike_rate_col, startbin = 30, endbin = 90) {
  spike_rate_col <- enquo(spike_rate_col)
  out_name <- sym(paste0(quo_name(spike_rate_col)))
  sr_unnest_name <- sym(paste0(quo_name(spike_rate_col), "_unnest"))
  fit_name <- sym(paste0(quo_name(out_name), "_fit"))
  glance_name <- sym(paste0(quo_name(out_name), "_glance"))
  r2_name <- sym(paste0(quo_name(out_name), "_r2_o"))
  Pval_name <- sym(paste0(quo_name(out_name), "_Pval_o"))
  slope_name <- sym(paste0(quo_name(out_name), "_slope_o"))
  intercept_name <- sym(paste0(quo_name(out_name), "_intercept_o"))
  df <- df %>%
    mutate(!!fit_name := map(!!spike_rate_col, bins=c(startbin:endbin), lm_helper),
           !!glance_name := map(!!fit_name, glance),
           !!r2_name := map_dbl(!!glance_name, ~.$r.squared),
           !!Pval_name := map_dbl(!!glance_name, ~.$p.value),
           !!slope_name := map_dbl(!!fit_name, ~.$coefficients[2]),
           !!intercept_name := map_dbl(!!fit_name, ~.$coefficients[1]))
}
```

3. run lm on all neurons
```{r}

spatial_firing <- spatial_firing %>%
  lm_analysis(asr_b_rewarded, 30, 90) %>%
  lm_analysis(shuff_asr_b, 30, 90) %>%
  lm_analysis(asr_p_rewarded, 30, 90)
  #lm_analysis(asr_nb_rewarded, 30, 90) 

```

4. Plot coefficients for all neurons
```{r}
ggplot(data=spatial_firing, aes(x = asr_b_rewarded_slope_o, y = asr_b_rewarded_r2_o)) + 
    coord_cartesian(xlim = c(-1,1), ylim = c(0,1)) +
    #geom_point(alpha=.4) + 
    geom_point() +
    xlab("\nslope") +
    ylab("R2") +
    theme_classic() +
    scale_color_manual(values=c("grey82", "grey32", "violetred2", "chartreuse3")) +
    theme(axis.text.x = element_text(size=12),
          axis.text.y = element_text(size=12),
          legend.position="bottom", 
          legend.title = element_blank(),
          text = element_text(size=12), 
          legend.text=element_text(size=12), 
          axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) 
ggsave(file = "plots/shuff_lm1_allcells.png", width = 4, height = 5)
```